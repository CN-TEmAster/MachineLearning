{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('spamSample2.txt', 'r') as f:\n",
    "    email = f.read()\n",
    "    print(email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import svm\n",
    "import re #regular expression for e-mail processing\n",
    "\n",
    "# 这是一个可用的英文分词算法(Porter stemmer)\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "# 这个英文算法似乎更符合作业里面所用的代码，与上面效果差不多\n",
    "import nltk, nltk.stem.porter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(email):\n",
    "    \"\"\"做除了Word Stemming和Removal of non-words的所有处理\"\"\"\n",
    "    email = email.lower()\n",
    "    email = re.sub('<[^<>]>', ' ', email)  # 匹配<开头，然后所有不是< ,> 的内容，知道>结尾，相当于匹配<...>\n",
    "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr', email )  # 匹配//后面不是空白字符的内容，遇到空白字符则停止\n",
    "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
    "    email = re.sub('[\\$]+', 'dollar', email)\n",
    "    email = re.sub('[\\d]+', 'number', email) \n",
    "    email = re.sub('[\\&]+', 'and', email) \n",
    "    email = re.sub('[\\%]+', 'percent', email) \n",
    "    return email\n",
    "def email2TokenList(email):\n",
    "    \"\"\"预处理数据，返回一个干净的单词列表\"\"\"\n",
    "    \n",
    "    # I'll use the NLTK stemmer because it more accurately duplicates the\n",
    "    # performance of the OCTAVE implementation in the assignment\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    \n",
    "    email = preProcess(email)\n",
    "\n",
    "    # 将邮件分割为单个单词，re.split() 可以设置多种分隔符\n",
    "    tokens = re.split('[ \\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\;\\%]', email)\n",
    "    \n",
    "    # 遍历每个分割出来的内容\n",
    "    tokenlist = []\n",
    "    for token in tokens:\n",
    "        # 删除任何非字母数字的字符\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token);\n",
    "        # Use the Porter stemmer to 提取词根\n",
    "        stemmed = stemmer.stem(token)\n",
    "        # 去除空字符串‘’，里面不含任何字符\n",
    "        if not len(token): continue\n",
    "        tokenlist.append(stemmed)\n",
    "            \n",
    "    return tokenlist  \n",
    "\n",
    "def email2VocabIndices(email, vocab):\n",
    "    \"\"\"提取存在单词的索引\"\"\"\n",
    "    token = email2TokenList(email)\n",
    "    index = [i for i in range(len(vocab)) if vocab[i] in token ]\n",
    "    return index\n",
    "def email2FeatureVector(email):\n",
    "    \"\"\"\n",
    "    将email转化为词向量，n是vocab的长度。存在单词的相应位置的值置为1，其余为0\n",
    "    \"\"\"\n",
    "    df = pd.read_table('vocab.txt',names=['words'])\n",
    "    vocab = df.values# return array\n",
    "    vector = np.zeros(len(vocab))  # init vector\n",
    "    vocab_indices = email2VocabIndices(email, vocab)  # 返回含有单词的索引\n",
    "    # 将有单词的索引置为1\n",
    "    for i in vocab_indices:\n",
    "        vector[i] = 1\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = preProcess(email)\n",
    "emain = email2TokenList(email)\n",
    "vector = email2FeatureVector(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99825, 0.989)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "mat1 = loadmat('spamTrain.mat')\n",
    "X, y = mat1['X'], mat1['y']\n",
    "\n",
    "# Test set\n",
    "mat2 = loadmat('spamTest.mat')\n",
    "Xtest, ytest = mat2['Xtest'], mat2['ytest']\n",
    "clf = svm.SVC(C=0.1, kernel='linear')\n",
    "clf.fit(X, y)\n",
    "predTrain = clf.score(X, y)\n",
    "predTest = clf.score(Xtest, ytest)\n",
    "predTrain, predTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([vector])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
